*****INTRODUCTION TO KUBERNETES*****
Container orchestration tool
Meant to manage containers whether that be containers from docker or elsewhere
Helps manage containerized applications in different deployment environments(physical machines, virtual machines, or cloud)
Kubernetes is also referred to as K8s

*****WHAT PROBLEM DOES KUBERNETES SOLVE*****
Trend from Monolith to Microservices
Rise of microservices caused increased usage of container technologies becuase containers offer the perfect host for small independent applications like microservices
This naturally caused an increased usage of containers
This caused a demand for a proper way of managing those hundreds of containers

*****FEATURES OF ORCHESTRATION TOOLS*****
High availability or no downtime(Availability)
	Your application is always accessible by users
Scalability or high performance(Scalability)
	Allows application to be more flexible to adjust to increase/decrease load
Disaster recovery - backup and restore(Recoverability)
	Containerized application can run from the latest state after recovery

*****KUBERNETES ARCHITECTURE*****
First lets define about some key terms and then talk about how they function
	Cluster = a set of nodes that run containerized applications
	Node = virtual or physical machine(Server)
	Master Node = Contains K8s processes that are absolutely necessary to run/manage the cluster properly
	Worker Nodes = Mostly referred to as Nodes, this is where you applications are running
	Pod = The smallest unit of execution in Kubernetes. A group of one or more containers
	Kubelet = Primary "node agent" which runs on each node and allows cluster to talk to each another
	API Server = Entrypoint to K8s cluster
	Controller Manager = Keeps track of what's happening in the cluster
	Scheduler = Ensures pod placement / decides on which worker Node new Pod should be scheduled
	etcd = K8s backing store
	Virtual Network = Creates one unified machine
	
What does all this mean though?
	The cluster is made up of one master node
	Connected to the master node are worker nodes
	Each worker node has containers of different applications deployed on it

Lets look at the master node closer
	As stated earlier the master node runs/manages the cluster properly
	How does it do this?
	With the help of K8s processes
	These processes include:
		API Server
			This itself is a container
			Entrypoint to K8s cluster
			This is the process that the different K8s clients will talk to
			Different K8s clients include:
				UI
					If you're using K8s dashboard
				API
					If you're using some scripts/automating technologies
				CLI
					kubectl get service
		Controller Manager
			This itself is a container
			Keeps an overview of what is happening in the cluster
			Monitors whether something needs to be repaired
			Monitors if a container dies and needs to be restarted
		Scheduler
			This itself is a container
			Responsible for scheduling containers on different nodes based on workload and available server resources on each node
				For example if 60% of node1 is being used and only 30% of node2 is being used it makes more sense to deploy containers on node2
		etcd
			Key-Value database store
			Holds the current state of the K8s cluster
			Has all the configuration data and all the status data of each node and each container inside of those nodes
			Allows you to recover the whole cluster state using etcd snapshot
	The above processes all occur within the master node

One important component of K8s that doesn't occur within the master node is the Virtual Network
	Virtual Network enables the worker nodes and master node to talk to one another
	Spans all the nodes that are part of the cluster
	Basically turns all the nodes inside of a cluster into one powerful unified machine that has the sum of all the resources of the individual nodes
	
Worker node vs Master node
	Worker nodes have higher workloads because they are the ones running the containers and as a result are much bigger and have more resources
	Master node only runs a handful of containers(the master processes we mentioned above) but it is much more important than individual worker nodes because if you
	lose a master node you won't be able to access the cluster anymore because it houses the API Server which is the entrypoint into the K8s cluster
	You absolutely have to have a backup of your Master node inside the K8s cluster
	
*****MAIN KUBERNETES COMPONENTS*****
Pod
Service
Ingress
ConfigMap
Secret
Deployment
StatefulSet
DaemonSet

*****Node and Pod*****
Node is a simple server, a physical or virtual machine
Pod is a basic component or smallest unit of execution in K8s
You can think of a pod as being wrapped around a container(s)
Containers are held within pods
Pod creates a running environment or a layer on top of the container, the reason for this is K8s wants to abstract away container technologies so you can replace them if you want to
and also so you don't have to directly work with docker or whatever container technology you're using in K8s
	Basically a pod creates a wrapper around the container so you can work with whatever container technology you want, be it docker or something else
	This ensures that you only work with the K8s layer
Usually 1 container(application) per pod
	You can run multiple containers inside one pod but that's only done when you have some helper container or some side service for a container that needs to run inside that pod
	
Lets take a look at how a simple application would look inside K8s
We will have our application pod that uses a db pod
 
 --------------------------------
|	 ------						 |
|	|my-app| <--application pod  |
|	 ------		(our app is		 |
|				container w/i	 |
|				a pod)			 |
|	------						 |
|  |  db  | <--db pod			 |
|   ------						 |
|								 |
|								 |
|			Node				 |
 --------------------------------
Above we have one server(node) and two containers(my-app and db) running on it with an abstraction layer(pod) on top of it

So how do they communicate with one another?
K8s offers out of the box a virtual network which means that each pod gets its own IP address
	Note: The container doesn't get an IP address, it's the pod that get it, be sure to make this distinction
Each pod can then communicate with one another using that IP address
The IP address is internal, it's not the public one
So my-app can communicate with db now
However pods are epehemeral, meaning that they can die
	Whether that be because the container itself crashes or the node that it's running in crashes pods can die
A new pod will be created to replace the old one, the problem with this is that it will be assigned a new IP address
Because of this issue another component called Service is used

Summary:
Pod
	Smallest executable unit in K8s
	Abstraction over container
	Usually 1 application per pod
	Each pod gets its own IP address
	New IP address on re-creation

*****SERVICE AND INGRESS*****
Service is a permanent IP address that can be attached to each pod
The lifecycle of the pod and service are not connected so even if the pod dies the IP address will remain the same
You want your application to be accessible through the browser and in order to achieve this you will want to create an external service
	External Service is a service that opens the communication from your app to external sources
	It's the way in which users can access your app via a web browser
But you wouldn't want you db to be open to external sources, so for that you would create an internal service
	Internal Service is the default type
You specify the type of Service on creation

The URL of the external service(my-app) is not very practical, it follows the format of http://node-ip:port#OfService
For example it could look something like this:
	http://124.89.101.2:8080
	The first set of numbers(124.89.101.2) represents the node IP address - not the service IP address but the node
	The second number(8080) is of the port number of the service
	This is not a good look for the end product, you can't expect users to remember these sets of numbers
	Ideally it should look something like http://my-app.com
	To acheive this there is a component called ingress

Ingress
So instead of the request first going to service it will go to ingress which will then forward the request to service
	Ingress receives the request and forwards it to the service

*****ConfigMap & Secret*****
As we stated earlier pods communicate with one another using a service
So how would my-app communicate with db
My-app would have a db endpoint(URL) that it uses to communicate with the db but where do you actually configure this db endpoint(URL)
Usually you would do it in application.properties file, usually it's inside the built image of the application
Lets say the endpoint of the db is called mongo-db-service, then that's what my-app would use to communicate with the db
But what happens if the name of the db changes from mongo-db-service to mongo-db?
You would have to adjust the URL in the application
This means re-building the application with the new version -> push it to the repo -> pull that new image into your pod
There is a solution though in the form of a K8s component called ConfigMap
	ConfigMap is the external configuration of your application
	ConfigMap usually contains configuration data like URL's of the db or other services that you use
	In order to use it you just connect it to the pod(in our case my-app) by referencing Secret in deployment/pod
	ConfigMap stores its data in plain text format
	Now if you change the name(endpoint) of the service you just adjust the ConfigMap and that's it, no need to go through the aforementioned steps
	You can use the data inside of ConfigMap inside of your pod by:
		Using environmental variables
		Using a properties file
	Usernames and passwords are also subject to change so your inclination might be to put that information in the ConfigMap also but ConfigMap is for non-confidential data only
	For this purpose K8s has another component called Secret

Secret
Is just like ConfigMap but it's used to store secret data(credentials)
In order to use it you just connect it to your pod by referencing Secret in deployment/pod
Secret stores its data in base-64 encoded format
This doesn't necessarily make it very secure though
Secret components are meant to be encrypted using 3rd party tools
You can use the data inside of ConfigMap inside of your pod by:
		Using environmental variables
		Using a properties file

*****VOLUME*****
How does data storage work in K8s?
In our example we have a db pod and it has some data and in our current set up if the pod gets restarted the data would be gone
This is a problem because you want your db data to be persistent
In order to acheive this you can use a K8s component called volumes
How does it work?
It basically attaches a physical storage on a hard drive to your pod
The storage can either be on:
	local machine(meaning on the same server node where the pod is running)
	remote storage(meaning outside of the K8s cluster) like cloud storage or your own premise storage
	Now if the pod gets restarted all the data will still be there
	So because K8s doesn't manage data persistence it's on you to do so
	Think of the storage as an external hard drive plug in into the K8s cluster

*****DEPLOYMENT AND STATEFULSET*****
Lets say for whatever reason your pod dies, this would result in downtime which means that the user can no longer reach my-app
This is where distributed systems comes into play
Instead of relying on just one my-app pod and one db pod you can replicate everything on multiple nodes
The replica is connected to the same Service(we talked about Service earlier - the permanent IP address)
Service will also act like a load balancer meaning it will catch the request and forward it to whichever pod is least busy
In order to create a second replica of my-app pod you wouldn't create a second my-app pod but rather you would define a blueprint for my-app pod and specify how many replicas of that pod you want to have
The blueprint is called Deployment
So in practice you would not be working with/creating pods but rather you would be creating deployments because there you can specify how many replicas you want
In addition to that you can also scale up/down the number of replicas of pods
So earlier we said that pods are a layer of abstraction on top of containers
Deployment is another layer of abstraction on top of pods which makes it more easier to interact with the pods, replicate them, and do other configurations
So in practice you would mostly work with deployments and not pods
Now if one of the replica pods of my-app were to die the Service will forward the request to another my-app replica

However the same does not apply to the db pod
DB can't be replicated via Deployment
DB pod has a 'state' which is its data meaning if we have replicas of the db they would all need to access the same shared data storage and there you would need some mechanism
that manages which pods are currently writing to that storage or which pods are reading from that storage in order to avoid data inconsistencies
That mechanism in addition to replicating feature is offered by another K8s component called StatefulSet
This component is meant specifically for applications like db's
So db's should be created using StatefulSet's and not Deployments
StatefulSets would take care of replicating the pods and scaling them up/down as well as making sure the db read/writes are synchronized so no db inconsistencies are present
Deploying StatefulSets is not easy
Because of this it is common practice to host db applications outside of the K8s cluster and just have the stateLESS apps inside the K8s cluster

Deployment - for stateLESS apps
StatefulSets = for stateFUL apps or databases

*****WRAP UP*****
Main K8s Components:
Pod - abstraction of containers
Service - communication
Ingress - route traffic into cluster
ConfigMap - external configuration
Secrets - external configuration
Volume - data persistence
Deployment - replication for stateLESS apps
StatefulSets - replication for stateFUL apps

All K8s clients(UI, API, or CLI) send their configuration requests to the API server
Requests have to be either in YAML or JSON format
API server is the only entrypoint into the cluster
Example configuration in YAML format:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
	  app: my-app
  template:
    metadata:
	  labels:
	    app: my-app
	spec:
	  container:
	    - name: my-app
		  image: my-image
		  env:
		    - name: SOME_ENV
			  value: $SOME_ENV
		  ports:
		    - containerPort: 8080
This example shows us sending a request to K8s to configure the component called Deployment
	Deployment = a template for creating pods
In this example we tell K8s to create two replica pods of my-app with each pod replica having a container based on my-image running inside
Also we configure what the environment variables and the port configuration of this container inside of the pod should be

*****3 PARTS OF A K8S CONFIGURATION FILE*****
Configuration files are used to create components
Every configuration file in K8s has 3 parts:
	metadata
	specification
	status

Lets look at a deployment and service yaml file to see it in action
	apiVersion: apps/v1													apiVersion: v1
	kind: Deployment													kind: Service
	metadata:															metadata:
	  name: nginx-deployment				  	  						  name: nginx-service
	  labels: ...(this represents info we won't bother typing)
	spec:																spec:
	  replicas: 2														  selector:
	  selector:	...														  ports:
	  template: ...
The first two lines just specifies what you want to create
	In our example we are creating deployment and service
Metadata - the metadata of the componenet that you're creating resides
		   one of the metadata is name of the component itself
Specification - Each components config file will have a specification where you put every kind of configuration that you want to apply for that component
				Attributes of specification are specific to the kind(i.e. attributes of deployment will be specific to deployment, attributes of service will be specific to service, etc...)
Status - Automatically generated and added by K8S
		 K8S will compare the desired state(i.e. 2 replicas, etc) vs the actual state
		 If the desired state and the actual state don't match then K8S will try and fix it
		 The etcd provides information that K8s uses to compare the desired vs actual status
		 So etcd holds the current status of any K8S component

*****FORMAT OF K8S CONFIGURATION FILE*****
"Human friendly" data serialization standard for all programming languages
Syntax: strict indentation (Code Editors have plugins for YAML syntax validation)
Usual practice is to store configuration files with your code because since deployment and service is going to be applied to your application it's good practice to store
these config files in your application code
Or you could have your own git repo for config files

*****WHAT IS MINIKUBE*****
Usually in K8S when you're setting up a production cluster it will look something like this:
	Multiple master and multiple worker nodes
	Each node(master or worker) would be set up on its own physical or virtual server
What about if you are working in your local environment or want to test something on your local environment and you don't have access to physical or virtual servers?
This is where minikube comes into play
Minikube is one node cluster but within that node is both the master and worker node processes both running on that one node
	Whereas usually one node is reserved for the master and another node reserved for the worker
This node will also have a docker container pre-installed
Minikube is just for start up/deleting the cluster

*****WHAT IS KUBECTL*****
Now that you have a virtual node on your local machine thanks to minikube you need a way to interact with the cluster
	You need a way to create pods and other K8S components on that node
You can achieve this by using kubectl
Kubectl is a command like tool for K8S cluster
As stated earlier the way you communicate with the cluster is through API server
	communication can occurr with 1 of 3 clients (UI, API, CLI)
	kubectl is a CLI
Once kubectl submites commands to the API server(Master processes) to create components, delete components, etc... the Worker processes actually make it happen(i.e executing
the command to create pods, delete pods, create services, etc...)
Kubectl isn't just for minkube cluster, if you have a cloud cluster or hybrid cluster, etc... kubectl is the tool used to interact with any type of K8s cluster setup
Kubectl us for configuring the minikube cluster

*****MINIKUBE/KUBECTL COMMANDS*****
Install minikube - minikube start --driver=virtualbox --no-vtx-check
	You have to download it first then install
	Also, minikube is very janky, I noticed that everytime I stopped it and tried using it again it wouldn't work
	One method to get it to work again is go to your VM and stop it and remove it from there
	Then delete minikube and run the install command again, you may have to do this multiple times as the install command may not work the first time
	
Delete minikube - minikube delete
	It's good practice to remove it from your VM before you run the delete command
	
Check minikube status - minkube status

Get status of nodes - kubectl get node