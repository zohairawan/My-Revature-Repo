*****INTRODUCTION TO KUBERNETES*****
Container orchestration tool
Meant to manage containers whether that be containers from docker or elsewhere
Helps manage containerized applications in different deployment environments(physical machines, virtual machines, or cloud)
Kubernetes is also referred to as K8s

*****WHAT PROBLEM DOES KUBERNETES SOLVE*****
Trend from Monolith to Microservices
Rise of microservices caused increased usage of container technologies becuase containers offer the perfect host for small independent applications like microservices
This naturally caused an increased usage of containers
This caused a demand for a proper way of managing those hundreds of containers

*****FEATURES OF ORCHESTRATION TOOLS*****
High availability or no downtime(Availability)
	Your application is always accessible by users
Scalability or high performance(Scalability)
	Allows application to be more flexible to adjust to increase/decrease load
Disaster recovery - backup and restore(Recoverability)
	Containerized application can run from the latest state after recovery

*****KUBERNETES ARCHITECTURE*****
First lets define about some key terms and then talk about how they function
	Cluster = a set of nodes that run containerized applications
	Node = virtual or physical machine(Server)
	Master Node = Contains K8s processes that are absolutely necessary to run/manage the cluster properly
	Worker Nodes = Mostly referred to as Nodes, this is where you applications are running
	Pod = The smallest unit of execution in Kubernetes. A group of one or more containers
	Kubelet = Primary "node agent" which runs on each node and allows cluster to talk to each another
	API Server = Entrypoint to K8s cluster
	Controller Manager = Keeps track of what's happening in the cluster
	Scheduler = Ensures pod placement / decides on which worker Node new Pod should be scheduled
	etcd = K8s backing store
	Virtual Network = Creates one unified machine
	
What does all this mean though?
	The cluster is made up of one master node
	Connected to the master node are worker nodes
	Each worker node has containers of different applications deployed on it

Lets look at the master node closer
	As stated earlier the master node runs/manages the cluster properly
	How does it do this?
	With the help of K8s processes
	These processes include:
		API Server
			This itself is a container
			Entrypoint to K8s cluster
			This is the process that the different K8s clients will talk to
			Different K8s clients include:
				UI
					If you're using K8s dashboard
				API
					If you're using some scripts/automating technologies
				CLI
		Controller Manager
			This itself is a container
			Keeps an overview of what is happening in the cluster
			Monitors whether something needs to be repaired
			Monitors if a container dies and needs to be restarted
		Scheduler
			This itself is a container
			Responsible for scheduling containers on different nodes based on workload and available server resources on each node
				For example if 60% of node1 is being used and only 30% of node2 is being used it makes more sense to deploy containers on node2
		etcd
			Key-Value database store
			Holds the current state of the K8s cluster
			Has all the configuration data and all the status data of each node and each container inside of those nodes
			Allows you to recover the whole cluster state using etcd snapshot
	The above processes all occur within the master node

One important component of K8s that doesn't occur within the master node is the Virtual Network
	Virtual Network enables the worker nodes and master node to talk to one another
	Spans all the nodes that are part of the cluster
	Basically turns all the nodes inside of a cluster into one powerful unified machine that has the sum of all the resources of the individual nodes
	
Worker node vs Master node
	Worker nodes have higher workloads because they are the ones running the containers and as a result are much bigger and have more resources
	Master node only runs a handful of containers(the master processes we mentioned above) but it is much more important than individual worker nodes because if you
	lose a master node you won't be able to access the cluster anymore because it houses the API Server which is the entrypoint into the K8s cluster
	You absolutely have to have a backup of your Master node inside the K8s cluster
	
*****MAIN KUBERNETES COMPONENTS*****
Pod
Service
Ingress
ConfigMap
Secret
Deployment
StatefulSet
DaemonSet

*****Node and Pod*****
Node is a simple server, a physical or virtual machine
Pod is a basic component or smallest unit of execution in K8s
You can think of a pod as being wrapped around a container(s)
Containers are held within pods
Pod creates a running environment or a layer on top of the container, the reason for this is K8s wants to abstract away container technologies so you can replace them if you want to
and also so you don't have to directly work with docker or whatever container technology you're using in K8s
	Basically a pod creates a wrapper around the container so you can work with whatever container technology you want, be it docker or something else
	This ensures that you only work with the K8s layer
Usually 1 container(application) per pod
	You can run multiple containers inside one pod but that's only done when you have some helper container or some side service for a container that needs to run inside that pod
	
Lets take a look at how a simple application would look inside K8s
We will have our application pod that uses a db pod
 
 --------------------------------
|	 ------						 |
|	|my-app| <--application pod  |
|	 ------		(our app is		 |
|				container w/i	 |
|				a pod)			 |
|	------						 |
|  |  db  | <--db pod			 |
|   ------						 |
|								 |
|								 |
|			Node				 |
 --------------------------------
Above we have one server(node) and two containers(my-app and db) running on it with an abstraction layer(pod) on top of it

So how do they communicate with one another?
K8s offers out of the box a virtual network which means that each pod gets its own IP address
	Note: The container doesn't get an IP address, it's the pod that get it, be sure to make this distinction
Each pod can then communicate with one another using that IP address
The IP address is internal, it's not the public one
So my-app can communicate with db now
However pods are epehemeral, meaning that they can die
	Whether that be because the container itself crashes or the node that it's running in crashes pods can die
A new pod will be created to replace the old one, the problem with this is that it will be assigned a new IP address
Because of this issue another component called Service is used

Summary:
Pod
	Smallest executable unit in K8s
	Abstraction over container
	Usually 1 application per pod
	Each pod gets its own IP address
	New IP address on re-creation

*****SERVICE AND INGRESS*****
